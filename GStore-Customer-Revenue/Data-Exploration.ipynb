{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhIf949sFLjR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import datetime\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'test_cleaned.csv', 'train_cleaned.csv', 'sample_submission.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'input/train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f393a57e90ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input/train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"fullVisitorId\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"str\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input/test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"fullVisitorId\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"str\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'input/train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"input/train.csv\", dtype={\"fullVisitorId\": \"str\"})\n",
    "test = pd.read_csv(\"input/test.csv\", dtype={\"fullVisitorId\": \"str\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train.fullVisitorId[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_json = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "dt_test = train.head(5)\n",
    "dt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, nrows=None):\n",
    "    columns_json = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    df = pd.read_csv(\n",
    "                        path, \n",
    "                        converters={column: json.loads for column in columns_json}, \n",
    "                        dtype={'fullVisitorId':'str'})\n",
    "    for column in columns_json:\n",
    "        df_columns_json = json_normalize(df[column])\n",
    "        df_columns_json.columns = [f\"{column}.{subcolumn}\" for subcolumn in df_columns_json.columns]\n",
    "        df = df.drop(column, axis=1).merge(df_columns_json, left_index=True, right_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = load_data(\"input/train.csv\")\n",
    "test = load_data(\"input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"input/train_extend.csv\", index=False)\n",
    "test.to_csv(\"input/test_extend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainset have 55 column while having 53 in testset. We knew that totals.transactionRevenue in training set is our target. We should find a column different between two set and drop it in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop = set(test.columns).difference(set(train.columns))\n",
    "print(col_drop)\n",
    "\n",
    "train = train.drop(col_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)\n",
    "print(\"target shape: \", target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to predict log(transactionRevenue) by training model using lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['totals.transactionRevenue']\n",
    "target = np.log1p(target.fillna(0).astype('float64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop all of constants columns in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_cols = [c for c in train.columns if train[c].nunique(dropna=False) == 1]\n",
    "const_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(const_cols, axis=1)\n",
    "test = test.drop(const_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (903653, 35)\n",
      "test shape:  (804684, 34)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"input/train_cleaned.csv\", dtype={'fullVisitorId':'str'})\n",
    "test = pd.read_csv(\"input/test_cleaned.csv\", dtype={'fullVisitorId':'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channelGrouping                                 0\n",
       "date                                            0\n",
       "fullVisitorId                                   0\n",
       "sessionId                                       0\n",
       "visitId                                         0\n",
       "visitNumber                                     0\n",
       "visitStartTime                                  0\n",
       "device.browser                                  0\n",
       "device.deviceCategory                           0\n",
       "device.isMobile                                 0\n",
       "device.operatingSystem                          0\n",
       "geoNetwork.city                                 0\n",
       "geoNetwork.continent                            0\n",
       "geoNetwork.country                              0\n",
       "geoNetwork.metro                                0\n",
       "geoNetwork.networkDomain                        0\n",
       "geoNetwork.region                               0\n",
       "geoNetwork.subContinent                         0\n",
       "totals.bounces                                  0\n",
       "totals.hits                                     0\n",
       "totals.newVisits                                0\n",
       "totals.pageviews                                0\n",
       "trafficSource.adContent                         0\n",
       "trafficSource.adwordsClickInfo.adNetworkType    0\n",
       "trafficSource.adwordsClickInfo.gclId            0\n",
       "trafficSource.adwordsClickInfo.isVideoAd        0\n",
       "trafficSource.adwordsClickInfo.page             0\n",
       "trafficSource.adwordsClickInfo.slot             0\n",
       "trafficSource.campaign                          0\n",
       "trafficSource.isTrueDirect                      0\n",
       "trafficSource.keyword                           0\n",
       "trafficSource.medium                            0\n",
       "trafficSource.referralPath                      0\n",
       "trafficSource.source                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_dt(train, test):\n",
    "    train = train.iloc[:,:-1] # the last columns is our target, we have done with this columns earlier step\n",
    "    missing_train = train.isnull().sum().values # array of all number of missing value per column\n",
    "    missing_test = test.isnull().sum().values\n",
    "    missing_train_per = missing_train/train.shape[0] # calculate percentage of missing value on total samples\n",
    "    missing_test_per = missing_test/test.shape[0]\n",
    "    return pd.DataFrame({\"missing value's percentage of training\": missing_train_per, \n",
    "                        \"missing value's percentage of testing\": missing_test_per}, \n",
    "                        index=train.columns).sort_values(\n",
    "                                by=[\"missing value's percentage of training\", \"missing value's percentage of testing\"], \n",
    "                                ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = check_missing_dt(train, test)\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just the way that i struggle to seperate categorical columns and numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = []\n",
    "num_cols = []\n",
    "for c in train.columns:\n",
    "    try:\n",
    "        train[c].astype(np.float64)\n",
    "        num_cols.append(str(c))\n",
    "    except ValueError:\n",
    "        cat_cols.append(str(c))\n",
    "print(\"categorical columns: \",cat_cols)\n",
    "print()\n",
    "print(\"numerical columns:\",num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we see on the numerical columns, there are some of columns classify like a numerical but naturelly these columns treat to reponse Yes No question, these columns are:**\n",
    "1. device.isMobile\n",
    "2. trafficSource.adwordsClickInfo.isVideoAd\n",
    "3. trafficSource.adwordsClickInfo.page\n",
    "4. trafficSource.isTrueDirect\n",
    "\n",
    "------------\n",
    "* fullVisitorId\n",
    "* sessionId\n",
    "* VisitId\n",
    "\n",
    "*SessionId* **and** *VisitId* **combine to** *fullVisitorId*, **but fullVisitorId is our target to predict transactionRevenue, it was be formated like string**\n",
    "\n",
    "------------\n",
    "**Because we will split data training based on time, so** *VisitStartTime* **will be drop from the numerical columns**\n",
    "\n",
    "------------\n",
    "**and finally,** *totals.transactionRevenue* **is our output, it should be split into seperated dataframe** ***target***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['visitNumber', \n",
    "            'visitStartTime', \n",
    "            'totals.bounces', \n",
    "            'totals.hits', \n",
    "            'totals.newVisits', \n",
    "            'totals.pageviews']\n",
    "cat_cols = ['channelGrouping', \n",
    "            'device.browser', \n",
    "            'device.deviceCategory', \n",
    "            'device.operatingSystem', \n",
    "            'geoNetwork.city', \n",
    "            'geoNetwork.continent', \n",
    "            'geoNetwork.country', \n",
    "            'geoNetwork.metro', \n",
    "            'geoNetwork.networkDomain', \n",
    "            'geoNetwork.region', \n",
    "            'geoNetwork.subContinent', \n",
    "            'trafficSource.adContent', \n",
    "            'trafficSource.adwordsClickInfo.adNetworkType', \n",
    "            'trafficSource.adwordsClickInfo.gclId', \n",
    "            'trafficSource.adwordsClickInfo.slot', \n",
    "            'trafficSource.campaign', \n",
    "            'trafficSource.keyword', \n",
    "            'trafficSource.medium', \n",
    "            'trafficSource.referralPath', \n",
    "            'trafficSource.source', \n",
    "            'device.isMobile', \n",
    "            'trafficSource.adwordsClickInfo.isVideoAd', \n",
    "            'trafficSource.adwordsClickInfo.page', \n",
    "            'trafficSource.isTrueDirect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(num_cols)+ len(cat_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    the function to plot the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = train['device.browser'].value_counts()[:6]\n",
    "print(device.values)\n",
    "trace = go.Bar(\n",
    "            x= device.index,\n",
    "            y= device.values,\n",
    "            showlegend=True,\n",
    "            marker = dict(\n",
    "                color='rgba(255,0,255,0.8)'\n",
    "            )\n",
    ")\n",
    "iplot([trace], filename=\"Device Browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cat(data, color, type_plot=None):\n",
    "    if type_plot=='Bar':\n",
    "        trace = go.Bar(\n",
    "            x = data.index[::-1],\n",
    "            y = data.values[::-1],\n",
    "            showlegend=False,\n",
    "            marker = dict(\n",
    "                color=color\n",
    "            )\n",
    "        )\n",
    "    elif type_plot=='Scatter':\n",
    "        trace = go.Scatter(\n",
    "            x = data.index[::-1],\n",
    "            y = data.values[::-1],\n",
    "            showlegend=False,\n",
    "            marker = dict(\n",
    "                color= color\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(\"choose your plot type\")\n",
    "        return\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show 3 subcolumns of device column: **\n",
    "* device.browser\n",
    "* device.deviceCategory\n",
    "* device.operatingSystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We explose each feature by our target that is totals.transactionRevenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#browser\n",
    "browser = train.groupby('device.browser')['totals.transactionRevenue'].agg(['size','count'])\n",
    "browser.columns = [\"count\", \"count of non-zero revenue\"]\n",
    "browser = browser.sort_values(by=\"count\", ascending=False)\n",
    "trace1 = plot_cat(browser[\"count\"].head(6), 'rgba(60,70,115,0.5)', 'Bar')\n",
    "trace2 = plot_cat(browser[\"count of non-zero revenue\"].head(6), 'rgba(210,157,37,0.9)', 'Bar')\n",
    "#deviceCategory\n",
    "category = train.groupby(\"device.deviceCategory\")[\"totals.transactionRevenue\"].agg(['size', 'count'])\n",
    "category.columns = [\"count\", \"count of non-zero revenue\"]\n",
    "category = category.sort_values(by=\"count\", ascending=False)\n",
    "trace3 = plot_cat(category[\"count\"].head(8), 'rgba(155,155,13,0.5)', 'Bar')\n",
    "trace4 = plot_cat(category[\"count of non-zero revenue\"].head(8), 'rgba(210,30,222,0.5)', 'Bar')\n",
    "#operatingSystem\n",
    "operating = train.groupby(\"device.operatingSystem\")[\"totals.transactionRevenue\"].agg(['size', 'count'])\n",
    "operating.columns = [\"count\", \"count of non-zero revenue\"]\n",
    "operating = operating.sort_values(by=\"count\", ascending=False)\n",
    "trace5 = plot_cat(operating[\"count\"].head(8), 'rgba(100,90,80,0.5)', 'Bar')\n",
    "trace6 = plot_cat(operating[\"count of non-zero revenue\"].head(8), 'rgba(60,99,123,0.5)', 'Bar')\n",
    "fig = tools.make_subplots(rows=3, cols=2, subplot_titles=[\"Browser - count\", \"Browser - Non Zero Revenue\",\n",
    "                                                          \"Category - count\", \"Category - Non Zero Revenue\",\n",
    "                                                          \"Operating System - count\", \"Operating System - Non Zero Revenue\"\n",
    "                                                         ])\n",
    "fig.append_trace(trace1, 1,1)\n",
    "fig.append_trace(trace2, 1,2)\n",
    "fig.append_trace(trace3, 2,1)\n",
    "fig.append_trace(trace4, 2,2)\n",
    "fig.append_trace(trace5, 3,1)\n",
    "fig.append_trace(trace6, 3,2)\n",
    "fig['layout'].update(height=1300, width=900, paper_bgcolor='rgb(233,233,233)', title=\"Device Plots\")\n",
    "iplot(fig, filename=\"device-plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = train['date'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d').date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2016, 9, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = train.groupby('date')['totals.transactionRevenue'].agg(['size', 'count'])\n",
    "date.columns = [\"count\", \"count of non-zero Revenue\"]\n",
    "date = date.sort_index()\n",
    "trace1 = plot_cat(date[\"count\"], 'red', 'Scatter')\n",
    "trace2 = plot_cat(date[\"count of non-zero Revenue\"], 'green', 'Scatter')\n",
    "fig = tools.make_subplots(rows=2, cols=1, subplot_titles=[\"count\", \"count of non zero revenue\"])\n",
    "fig['layout'].update(height=800, width=1000, title=\"Date plots\", paper_bgcolor='rgba(233,233,233,0.4)')\n",
    "fig.append_trace(trace1, 1,1)\n",
    "fig.append_trace(trace2, 2, 1)\n",
    "iplot(fig, filename=\"date-plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_visit_per_id = train.groupby(\"fullVisitorId\")[\"visitNumber\"].agg(['size', 'count'])\n",
    "num_visit_per_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_visit_per_id = train.groupby(\"fullVisitorId\")[\"visitNumber\"].agg(['size', 'count'])\n",
    "num_visit_per_id.columns = [\"count\", \"count of non zero revenue\"]\n",
    "num_visit_per_id.sort_values(by=\"count\", ascending=False, inplace=True)\n",
    "trace1 = plot_cat(num_visit_per_id[\"count\"].head(20), 'rgba(145,210,50,0.5)', 'Bar')\n",
    "trace2 = plot_cat(num_visit_per_id[\"count of non zero revenue\"].head(20), 'rgba(145,210,50,0.5)', 'Bar')\n",
    "fig = tools.make_subplots(rows=2, cols=1, subplot_titles=[\"Count\", \"Count of non zero revenue\"])\n",
    "fig.append_trace(trace1, 1,1)\n",
    "fig.append_trace(trace2, 2,1)\n",
    "fig['layout'].update(height=1200, width=900, paper_bgcolor='rgba(233,233,233,0.5)', title=\"Revenue per visitor id\")\n",
    "iplot(fig, filename=\"revenue-visitor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in cat_cols:\n",
    "    lbd = LabelEncoder()\n",
    "    lbd.fit(list(train[col].values.astype('str')) + list(test[col].values.astype('str')))\n",
    "    train[col] = lbd.transform(list(train[col].values.astype('str')))\n",
    "    test[col] = lbd.transform(list(test[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    train[col] = train[col].fillna(0).astype('float')\n",
    "    test[col] = test[col].fillna(0).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"totals.transactionRevenue\"].fillna(0, inplace=True)\n",
    "y_train = train[\"totals.transactionRevenue\"].values\n",
    "drop_col = set(train.columns).difference(set(cat_cols + num_cols))\n",
    "drop_col = list(drop_col) + [\"VisitStartTime\"]\n",
    "drop_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sessionId'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['visitId'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fullVisitorId'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['visitStartTime'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse(y_true, y_pred):\n",
    "    return round(np.sqrt(mean_squared_error(y_true, y_pred)), 5)\n",
    "\n",
    "def run_lgb(X_train, y_train, X_val, y_val, X_test):\n",
    "    data_train = lgb.Dataset(X_train, label=y_train)\n",
    "    data_val = lgb.Dataset(X_val, label=y_val)\n",
    "    param = {\n",
    "         'objective':'regression',\n",
    "         'metric': 'rmse',\n",
    "         'learning_rate':0.005,\n",
    "         'num_leaves':40,\n",
    "         'min_data_in_leaf':150,\n",
    "         'max_depth':10,\n",
    "         'bagging_fraction':0.6,\n",
    "         'feature_fraction':0.6,\n",
    "         'bagging_frequency': 6,\n",
    "         'verbosity':-1,\n",
    "         'random_state': 42}\n",
    "    model = lgb.train(param, data_train, valid_sets=[data_train, data_val], num_boost_round=5000, early_stopping_rounds=100,\n",
    "                  verbose_eval=200)\n",
    "    pred_y_test = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    \n",
    "    return pred_y_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train dataset into train and valid based on time\n",
    "X_train_df = train[train[\"date\"]<=datetime.date(2017,5,31)]\n",
    "X_val_df = train[train[\"date\"]>datetime.date(2017,5,31)]\n",
    "y_train = np.log1p(X_train_df[\"totals.transactionRevenue\"].values)\n",
    "y_val = np.log1p(X_val_df[\"totals.transactionRevenue\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608481,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608481, 31)\n",
      "608481\n"
     ]
    }
   ],
   "source": [
    "y_train = np.log1p(X_train_df[['fullVisitorId','totals.transactionRevenue']].groupby('fullVisitorId').sum().values.ravel())\n",
    "X_train_df = X_train_df[cat_cols + num_cols + ['fullVisitorId']].groupby('fullVisitorId').mean().reset_index()\n",
    "print(X_train_df.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110252, 31)\n",
      "110252\n"
     ]
    }
   ],
   "source": [
    "y_val = np.log1p(X_val_df[['fullVisitorId','totals.transactionRevenue']].groupby('fullVisitorId').sum().values.ravel())\n",
    "X_val_df = X_val_df[cat_cols + num_cols + ['fullVisitorId']].groupby('fullVisitorId').mean().reset_index()\n",
    "print(X_val_df.shape)\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617242, 31)\n"
     ]
    }
   ],
   "source": [
    "test_df = test[cat_cols + num_cols + ['fullVisitorId']].groupby('fullVisitorId').mean().reset_index()\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_df[num_cols + cat_cols]\n",
    "X_val = X_val_df[num_cols + cat_cols]\n",
    "X_test = test[num_cols + cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's rmse: 0.28276\tvalid_1's rmse: 0.302188\n",
      "[400]\ttraining's rmse: 0.270983\tvalid_1's rmse: 0.288486\n",
      "[600]\ttraining's rmse: 0.265912\tvalid_1's rmse: 0.283481\n",
      "[800]\ttraining's rmse: 0.263015\tvalid_1's rmse: 0.281427\n",
      "[1000]\ttraining's rmse: 0.261247\tvalid_1's rmse: 0.280503\n",
      "[1200]\ttraining's rmse: 0.260001\tvalid_1's rmse: 0.280025\n",
      "[1400]\ttraining's rmse: 0.259134\tvalid_1's rmse: 0.279771\n",
      "[1600]\ttraining's rmse: 0.258435\tvalid_1's rmse: 0.279613\n",
      "[1800]\ttraining's rmse: 0.257823\tvalid_1's rmse: 0.279549\n",
      "Early stopping, best iteration is:\n",
      "[1866]\ttraining's rmse: 0.257661\tvalid_1's rmse: 0.279545\n"
     ]
    }
   ],
   "source": [
    "pred_test, model = run_lgb(X_train, y_train, X_val, y_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test.copy()\n",
    "test_df['predictions'] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_pred_list = test_df[['fullVisitorId', 'predictions']].groupby('fullVisitorId')\\\n",
    "    .apply(lambda df: list(df.predictions))\\\n",
    "    .apply(lambda x: {'pred_'+str(i): pred for i, pred in enumerate(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = test[num_cols + cat_cols + ['fullVisitorId']].groupby('fullVisitorId').mean()\n",
    "sub_all_predictions = pd.DataFrame(list(sub_pred_list.values), index=sub_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617242, 272)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_all_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.285425059978261\n"
     ]
    }
   ],
   "source": [
    "#pred_y[pred_y<0] = 0\n",
    "val_pred_df = pd.DataFrame({\"fullVisitorId\":X_val_df[\"fullVisitorId\"].values})\n",
    "val_pred_df[\"transactionRevenue\"] = X_val_df[\"totals.transactionRevenue\"].values\n",
    "val_pred_df[\"PredictedRevenue\"] = np.expm1(pred_y)\n",
    "\n",
    "val_pred_df = val_pred_df.groupby(\"fullVisitorId\")[\"transactionRevenue\", \"PredictedRevenue\"].sum().reset_index()\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(np.sqrt(mean_squared_error(np.log1p(val_pred_df[\"transactionRevenue\"].values), \n",
    "                                 np.log1p(val_pred_df[\"PredictedRevenue\"].values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(test[num_cols + cat_cols], num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test[pred_test<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test[['fullVisitorId']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[:,'PredictedLogRevenue'] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_test = submission[['fullVisitorId', 'PredictedLogRevenue']].groupby('fullVisitorId').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617242, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_test.to_csv(\"input/submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"input/train_work.csv\", index=False)\n",
    "test.to_csv(\"input/test_work.csv\", index=False)\n",
    "target.to_csv(\"input/target_work.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"input/train_work.csv\", dtype={'fullVisitorId':'str'})\n",
    "test = pd.read_csv(\"input/test_work.csv\", dtype={'fullVisitorId':'str'})\n",
    "target = pd.read_csv(\"input/target_work.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903653, 35)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804684, 34)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>device.browser</th>\n",
       "      <th>device.deviceCategory</th>\n",
       "      <th>device.operatingSystem</th>\n",
       "      <th>geoNetwork.city</th>\n",
       "      <th>geoNetwork.continent</th>\n",
       "      <th>geoNetwork.country</th>\n",
       "      <th>geoNetwork.metro</th>\n",
       "      <th>geoNetwork.networkDomain</th>\n",
       "      <th>...</th>\n",
       "      <th>device.isMobile</th>\n",
       "      <th>trafficSource.adwordsClickInfo.isVideoAd</th>\n",
       "      <th>trafficSource.adwordsClickInfo.page</th>\n",
       "      <th>trafficSource.isTrueDirect</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>totals.bounces</th>\n",
       "      <th>totals.hits</th>\n",
       "      <th>totals.newVisits</th>\n",
       "      <th>totals.pageviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000259678714014</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>19362.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.511913e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000049363351866189</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>540.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.505813e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000053049821714864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>955.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>29081.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.517179e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000059488412965267</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.519587e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000085840370633780</td>\n",
       "      <td>4.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>749.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.504919e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fullVisitorId  channelGrouping  device.browser  \\\n",
       "0  0000000259678714014              4.0            35.0   \n",
       "1  0000049363351866189              2.0            35.0   \n",
       "2  0000053049821714864              1.0            73.0   \n",
       "3  0000059488412965267              2.0            35.0   \n",
       "4  0000085840370633780              4.0            72.0   \n",
       "\n",
       "   device.deviceCategory  device.operatingSystem  geoNetwork.city  \\\n",
       "0                    0.0                     7.0       540.000000   \n",
       "1                    0.0                     3.0       540.333333   \n",
       "2                    1.0                    23.0       955.000000   \n",
       "3                    1.0                     1.0       182.000000   \n",
       "4                    0.0                     7.0       749.000000   \n",
       "\n",
       "   geoNetwork.continent  geoNetwork.country  geoNetwork.metro  \\\n",
       "0                   2.0               218.0        100.000000   \n",
       "1                   3.0                93.0         40.666667   \n",
       "2                   2.0                 9.0        122.000000   \n",
       "3                   2.0               218.0         19.000000   \n",
       "4                   2.0               218.0        100.000000   \n",
       "\n",
       "   geoNetwork.networkDomain        ...         device.isMobile  \\\n",
       "0                   19362.5        ...                     0.0   \n",
       "1                       0.0        ...                     0.0   \n",
       "2                   29081.0        ...                     1.0   \n",
       "3                       0.0        ...                     1.0   \n",
       "4                       0.0        ...                     0.0   \n",
       "\n",
       "   trafficSource.adwordsClickInfo.isVideoAd  \\\n",
       "0                                       1.0   \n",
       "1                                       1.0   \n",
       "2                                       1.0   \n",
       "3                                       1.0   \n",
       "4                                       1.0   \n",
       "\n",
       "   trafficSource.adwordsClickInfo.page  trafficSource.isTrueDirect  \\\n",
       "0                                 11.0                         0.5   \n",
       "1                                 11.0                         0.0   \n",
       "2                                 11.0                         1.0   \n",
       "3                                 11.0                         0.0   \n",
       "4                                 11.0                         1.0   \n",
       "\n",
       "   visitNumber  visitStartTime  totals.bounces  totals.hits  totals.newVisits  \\\n",
       "0          1.5    1.511913e+09             0.0          9.5          0.500000   \n",
       "1          2.0    1.505813e+09             1.0          1.0          0.333333   \n",
       "2          1.0    1.517179e+09             1.0          1.0          1.000000   \n",
       "3          2.0    1.519587e+09             1.0          1.0          0.333333   \n",
       "4          1.0    1.504919e+09             0.0          2.0          1.000000   \n",
       "\n",
       "   totals.pageviews  \n",
       "0               6.5  \n",
       "1               1.0  \n",
       "2               1.0  \n",
       "3               1.0  \n",
       "4               2.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = test[cat_cols + num_cols + ['fullVisitorId']].groupby('fullVisitorId').mean().reset_index()\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714167, 30)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = train[cat_cols + num_cols + ['fullVisitorId']].groupby('fullVisitorId').mean()\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sub, model = run_lgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data Frame we working:\n",
    "train.to_csv(\"input/train_cleaned.csv\", index=False)\n",
    "test.to_csv(\"input/test_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"input/sample_submission.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(submit['fullVisitorId']).intersection(set(test['fullVisitorId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['fullVisitorId'].unique().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data-Exploration.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
